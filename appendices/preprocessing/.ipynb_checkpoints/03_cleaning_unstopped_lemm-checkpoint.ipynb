{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bf8017d-8e9b-4acd-93e0-9967e6c5fc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c0d9cf0-b575-4671-babd-752ff0687efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../datasets/unstopped_text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f8be5fd-54fe-4f6f-8f02-5d14d010cf36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unstopped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>add diagnosis??? recently got health insurance...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>question tell loved ones actually it?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>any good advice? ive tried hard overcome depre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>am suffering depression? feel unmotivated ever...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cada vez un poco más en la mierda estado toman...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           unstopped\n",
       "0  add diagnosis??? recently got health insurance...\n",
       "1              question tell loved ones actually it?\n",
       "2  any good advice? ive tried hard overcome depre...\n",
       "3  am suffering depression? feel unmotivated ever...\n",
       "4  cada vez un poco más en la mierda estado toman..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afb606c5-5d5d-49ff-8e4f-49cfdb207405",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok1 = RegexpTokenizer(r'\\w+')\n",
    "tok2 = RegexpTokenizer('\\w+|\\$[\\d\\.]+|\\S+')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d765f08b-b306-485e-8093-7d6e9cd443aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['unst_simp_lem'] = df['unstopped'].map(lambda x: ' '.join(tok1.tokenize(x)))\n",
    "df['unst_simp_lem'] = df['unst_simp_lem'].map(lambda x: ' '.join([lemmatizer.lemmatize(word) for word in x.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "224a60ff-ddff-4883-9c96-bf1a9074e8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df['unst_simp_lem']).to_csv('../../datasets/unst_simp_lem.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e06249d-b2d5-43cf-92e5-576a7e0ffb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['unst_comp_lem'] = df['unstopped'].map(lambda x: ' '.join(tok2.tokenize(x)))\n",
    "df['unst_comp_lem'] = df['unst_comp_lem'].map(lambda x: ' '.join([lemmatizer.lemmatize(word) for word in x.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "518c1ca3-4fcf-4021-a319-ecdcd4f49327",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df['unst_comp_lem']).to_csv('../../datasets/unst_comp_lem.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fed85e-e997-4fb5-8f9f-81144f3aa65c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
